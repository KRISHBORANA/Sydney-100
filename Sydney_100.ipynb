{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5GZzLwDdbta"
   },
   "source": [
    "Code for User.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_r4TvgJZTvS6",
    "outputId": "d51f707a-b976-4cea-dd8f-fc03387f0c6f"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.exceptions import RequestException\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# GitHub API endpoint and headers\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "GITHUB_TOKEN = \"Replace with your GitHub token\"  # Replace with your GitHub token\n",
    "\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}\n",
    "\n",
    "# Session with retry and backoff\n",
    "session = requests.Session()\n",
    "retry_strategy = Retry(\n",
    "    total=5,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "def fetch_sydney_users(min_followers=100):\n",
    "    \"\"\"Fetch GitHub users in Sydney with more than the specified number of followers.\"\"\"\n",
    "    users = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            url = f\"{GITHUB_API_URL}/search/users?q=location:Sydney+followers:>{min_followers}&page={page}&per_page=100\"\n",
    "            response = session.get(url, timeout=10)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "            data = response.json()\n",
    "            if not data['items']:\n",
    "                break\n",
    "\n",
    "            for user in data['items']:\n",
    "                user_details = fetch_user_details(user[\"login\"], user[\"url\"])\n",
    "                if user_details:\n",
    "                    users.append(user_details)\n",
    "\n",
    "            page += 1\n",
    "            if page > 10:\n",
    "                break\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        except RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            break\n",
    "\n",
    "    return users\n",
    "\n",
    "def fetch_user_details(login, user_detail_url):\n",
    "    \"\"\"Fetch detailed information for a specific user.\"\"\"\n",
    "    response = session.get(user_detail_url, timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        user_data = response.json()\n",
    "        return {\n",
    "            \"login\": user_data.get(\"login\", \"\"),\n",
    "            \"name\": user_data.get(\"name\", \"\"),\n",
    "            \"company\": (user_data.get(\"company\") or \"\").lstrip(\"@\").upper().strip(),\n",
    "            \"location\": user_data.get(\"location\", \"\"),\n",
    "            \"email\": user_data.get(\"email\", \"\"),\n",
    "            \"hireable\": user_data.get(\"hireable\", \"\"),\n",
    "            \"bio\": user_data.get(\"bio\", \"\"),\n",
    "            \"public_repos\": user_data.get(\"public_repos\", 0),\n",
    "            \"followers\": user_data.get(\"followers\", 0),\n",
    "            \"following\": user_data.get(\"following\", 0),\n",
    "            \"created_at\": user_data.get(\"created_at\", \"\")\n",
    "        }\n",
    "    else:\n",
    "        error_message = response.json().get('message', 'No additional error info')\n",
    "        print(f\"Failed to fetch details for {login}: {response.status_code} - {error_message}\")\n",
    "    return None\n",
    "\n",
    "# Fetch users and save to 'users.csv'\n",
    "sydney_users = fetch_sydney_users()\n",
    "df_users = pd.DataFrame(sydney_users)\n",
    "df_users.to_csv(\"users.csv\", index=False)\n",
    "print(\"Detailed user data saved to users.csv successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLwebWzAik3R"
   },
   "source": [
    "#more cleaned users.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6Gt4LSAijPN",
    "outputId": "2e2ce66b-20a1-467e-be37-2ccfe53a4257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company names cleaned and saved to users.csv.\n"
     ]
    }
   ],
   "source": [
    "#more cleaned users.csv\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Clean the company names\n",
    "users_df['company'] = users_df['company'].str.strip()  # Trim whitespace\n",
    "users_df['company'] = users_df['company'].str.lstrip('@')  # Strip leading '@'\n",
    "users_df['company'] = users_df['company'].str.upper()  # Convert to uppercase\n",
    "\n",
    "# Save the cleaned DataFrame back to users.csv\n",
    "users_df.to_csv('users.csv', index=False)\n",
    "\n",
    "print(\"Company names cleaned and saved to users.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGrWYzNldNPf"
   },
   "source": [
    "Download User.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "990FxovqZi2A",
    "outputId": "2d0e74e1-60f9-4463-93cf-f9b840d784f6"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_19d05cc5-2209-4b87-ac48-ce4d53a08165\", \"users.csv\", 51795)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download users.csv\n",
    "files.download(\"users.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmcQ2YphdE4v"
   },
   "source": [
    "Code for repositories.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17a1fTxfbMUZ",
    "outputId": "d336fcd0-e72e-409d-c3e7-7d31649562e5"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.exceptions import RequestException\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# GitHub API endpoint and headers\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "GITHUB_TOKEN = \"Replace with your GitHub token\"  # Replace with your GitHub token\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}\n",
    "\n",
    "# Session with retry and backoff\n",
    "session = requests.Session()\n",
    "retry_strategy = Retry(\n",
    "    total=5,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "def fetch_user_repositories(login):\n",
    "    \"\"\"Fetch public repositories for a given user.\"\"\"\n",
    "    repos = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        try:\n",
    "            url = f\"{GITHUB_API_URL}/users/{login}/repos?page={page}&per_page=100\"\n",
    "            response = session.get(url, timeout=10)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error fetching repos for {login}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "            repo_data = response.json()\n",
    "            if not repo_data:\n",
    "                break\n",
    "\n",
    "            for repo in repo_data:\n",
    "                repos.append({\n",
    "                    \"login\": login,\n",
    "                    \"full_name\": repo.get(\"full_name\", \"\"),\n",
    "                    \"created_at\": repo.get(\"created_at\", \"\"),\n",
    "                    \"stargazers_count\": repo.get(\"stargazers_count\", 0),\n",
    "                    \"watchers_count\": repo.get(\"watchers_count\", 0),\n",
    "                    \"language\": repo.get(\"language\", \"\"),\n",
    "                    \"has_projects\": repo.get(\"has_projects\", False),\n",
    "                    \"has_wiki\": repo.get(\"has_wiki\", False),\n",
    "                    \"license_name\": repo.get(\"license\").get(\"key\", \"\") if repo.get(\"license\") else \"\"\n",
    "                })\n",
    "            page += 1\n",
    "            time.sleep(1)  # To avoid hitting the rate limit\n",
    "        except RequestException as e:\n",
    "            print(f\"Request failed for {login}: {e}\")\n",
    "            break\n",
    "\n",
    "    return repos\n",
    "\n",
    "# Read users from 'users.csv'\n",
    "users_df = pd.read_csv(\"users.csv\")\n",
    "\n",
    "# Initialize a list to store repository data\n",
    "all_repos = []\n",
    "\n",
    "# Loop through each user and fetch their repositories\n",
    "for index, row in users_df.iterrows():\n",
    "    login = row[\"login\"]\n",
    "    print(f\"Fetching repositories for user: {login}\")\n",
    "    user_repos = fetch_user_repositories(login)\n",
    "    all_repos.extend(user_repos)  # Append fetched repositories\n",
    "\n",
    "# Save repositories to 'repositories.csv'\n",
    "df_repositories = pd.DataFrame(all_repos)\n",
    "df_repositories.to_csv(\"repositories.csv\", index=False)\n",
    "print(\"Repository data saved to repositories.csv successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LfJStvydBkz"
   },
   "source": [
    "Code to Download repositories.csv from Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Nj_HyBFac-Bp",
    "outputId": "9e83f71c-b2d3-4fc6-c3f9-0ec5d3fe5d2f"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_5a58e6f0-6da0-4cb7-8e4a-688b1fbada2a\", \"repositories.csv\", 3779317)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Assuming 'repositories.csv' is the file you want to download\n",
    "file_name = 'repositories.csv'  # Change this to your file name if needed\n",
    "\n",
    "# Download the file\n",
    "files.download(file_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
